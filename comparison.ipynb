{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4da3582",
   "metadata": {},
   "source": [
    "# Comparison between dictionary keys of pretrained model and raw one"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18227a1",
   "metadata": {},
   "source": [
    "There is a descrepancy between real Pi3 encoder/decoder dictionary keys and how MVGGT handles them.\n",
    "\n",
    "See changes in encoder/decoder treatment:\n",
    "- Encoder: https://github.com/vasabi-root/mvggt/commit/0ce4d1f0248fbd1f1a160c600c0d01e1c6052329\n",
    "- Decoder: https://github.com/vasabi-root/mvggt/commit/ff33729e9bc1d350972823b663de1250475455e7\n",
    "\n",
    "Pi3 and Pi3x were downloaded from official Pi3 repo: https://github.com/yyfz/Pi3/tree/08d7288aaf4b0c08c8498bea7bafedc4672bb006:\n",
    "- Pi3: https://huggingface.co/yyfz233/Pi3/resolve/main/model.safetensors\n",
    "- Pi3x: https://huggingface.co/yyfz233/Pi3X/resolve/main/model.safetensors\n",
    "\n",
    "Notebook below shows, why this changes are necessary. MVGGT models were loaded with changed encoder/decoder treatment, because, as shown in [Aggregators](#aggregators) section, neither Pi3 nor Pi3x have 'aggregator.' keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5633c26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning, cannot find cuda-compiled version of RoPE2D, using a slow pytorch version instead\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from mvggt.models.mvggt_training import MVGGT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73709f8f",
   "metadata": {},
   "source": [
    "## Raw model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a191127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vggt encoder <All keys matched successfully>\n",
      "Loading vggt decoder <All keys matched successfully>\n",
      "Freezing all visual modules for referring segmentation training.\n"
     ]
    }
   ],
   "source": [
    "model_raw =  MVGGT(\n",
    "    use_referring_segmentation=True,\n",
    "    freeze_visual_modules=True,           # frozen Pi3/VGGT visual\n",
    "    freeze_encoder=True,\n",
    "    num_multimodal_layers=12,             # from the article\n",
    "    multimodal_layer_selection='back',\n",
    "    fusion_mode='pwa_only',               # can be 'interleaved', but in the article only \"point-wise add\" used\n",
    "    use_lang_vision_fusion=False,\n",
    "    use_controlnet_injection=True,\n",
    "    use_lora=False,                       # True to fine-tune decoder\n",
    "    text_model_name=\"roberta-base\",\n",
    "    load_vggt=True,                       # Pi3 encoder/decoder or vggt...\n",
    "    use_pretrained_weights=False          # loads Pi3 VGGT decoder (as multimodal_decoder)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691a7685",
   "metadata": {},
   "source": [
    "## Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7469ec07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Freezing the encoder.\n",
      "[MVGGT] Load checkpoints from /home/bashmac/MIPT/VLM/mvggt/ckpts/pytorch_model.bin: <All keys matched successfully>\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = '/home/bashmac/MIPT/VLM/mvggt/ckpts/pytorch_model.bin'\n",
    "model_pretrained = MVGGT(\n",
    "    use_referring_segmentation=True, \n",
    "    load_vggt=False, \n",
    "    train_conf=True, \n",
    "    ckpt=ckpt_path,\n",
    "    use_pretrained_weights=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b7f829",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33a6ddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List, Dict\n",
    "\n",
    "def compare_models_dicts(model1_dict: Dict, model2_dict: Dict) -> Tuple[List[str]]:\n",
    "    keys_model1 = model1_dict.keys()\n",
    "    keys_model2 = model2_dict.keys()\n",
    "    \n",
    "    # Are there keys from model1, that is not presented in model2?\n",
    "    kyes_only_in_model1 = []\n",
    "    for key in keys_model1:\n",
    "        if key not in keys_model2:\n",
    "            kyes_only_in_model1.append(key)\n",
    "\n",
    "    \n",
    "    # Are there keys from model2, that is not presented in model1?\n",
    "    kyes_only_in_model2 = []\n",
    "    for key in keys_model2:\n",
    "        if key not in keys_model1:\n",
    "            kyes_only_in_model2.append(key)\n",
    "            \n",
    "    return kyes_only_in_model1, kyes_only_in_model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53a998e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How many keys from model_raw are not presented in model_pretrained?\n",
      "A: 0\n",
      "\n",
      "Q: How many keys from model_pretrained are not presented in model_raw?\n",
      "A: 0\n"
     ]
    }
   ],
   "source": [
    "kyes_only_in_raw, kyes_only_in_pretrained = compare_models_dicts(model_raw.state_dict(), model_pretrained.state_dict())\n",
    "\n",
    "print(f'Q: How many keys from model_raw are not presented in model_pretrained?')\n",
    "print(f'A: {len(kyes_only_in_raw)}')\n",
    "print()\n",
    "print(f'Q: How many keys from model_pretrained are not presented in model_raw?')\n",
    "print(f'A: {len(kyes_only_in_pretrained)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4515d8e7",
   "metadata": {},
   "source": [
    "# Comparison between dictionary keys of Pi3 model and Pi3x\n",
    "\n",
    "- Pi3: https://huggingface.co/yyfz233/Pi3/resolve/main/model.safetensors (renamed to `ckpts/VGGT-1B/pi3.safetensors`)\n",
    "- Pi3x: https://huggingface.co/yyfz233/Pi3X/resolve/main/model.safetensors (renamed to `ckpts/VGGT-1B/pi3x.safetensors`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e61766eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from safetensors.torch import load_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e522bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi3 = load_file('ckpts/VGGT-1B/pi3.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc15df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi3x = load_file('ckpts/VGGT-1B/pi3x.safetensors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c64f344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_pi3s_comparison(pi3, pi3x):\n",
    "    kyes_only_in_pi3, kyes_only_in_pi3x = compare_models_dicts(pi3, pi3x)\n",
    "\n",
    "    print(f'Q: How many keys from pi3 are not presented in pi3x?')\n",
    "    print(f'A: {len(kyes_only_in_pi3)}')\n",
    "    print()\n",
    "    print(f'Q: How many keys from pi3x are not presented in pi3?')\n",
    "    print(f'A: {len(kyes_only_in_pi3x)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab6e12ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How many keys from pi3 are not presented in pi3x?\n",
      "A: 4\n",
      "\n",
      "Q: How many keys from pi3x are not presented in pi3?\n",
      "A: 667\n"
     ]
    }
   ],
   "source": [
    "print_pi3s_comparison(pi3, pi3x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fff1451",
   "metadata": {},
   "source": [
    "## Encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb8290bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How many keys from pi3 are not presented in pi3x?\n",
      "A: 0\n",
      "\n",
      "Q: How many keys from pi3x are not presented in pi3?\n",
      "A: 0\n"
     ]
    }
   ],
   "source": [
    "pi3_encoder = {key:pi3[key] for key in pi3.keys() if key.startswith('encoder.')}\n",
    "pi3x_encoder = {key:pi3x[key] for key in pi3x.keys() if key.startswith('encoder.')}\n",
    "\n",
    "print_pi3s_comparison(pi3_encoder, pi3x_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd49dd53",
   "metadata": {},
   "source": [
    "## Decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "571134ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q: How many keys from pi3 are not presented in pi3x?\n",
      "A: 0\n",
      "\n",
      "Q: How many keys from pi3x are not presented in pi3?\n",
      "A: 0\n"
     ]
    }
   ],
   "source": [
    "pi3_decoder = {key:pi3[key] for key in pi3.keys() if key.startswith('decoder.')}\n",
    "pi3x_decoder = {key:pi3x[key] for key in pi3x.keys() if key.startswith('decoder.')}\n",
    "\n",
    "print_pi3s_comparison(pi3_decoder, pi3x_decoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2736d2cf",
   "metadata": {},
   "source": [
    "## Aggregators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a95b69a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of pi3 \"aggregator.\": 0\n",
      "Len of pi3x \"aggregator.\": 0\n"
     ]
    }
   ],
   "source": [
    "pi3_aggregator = {key:pi3[key] for key in pi3.keys() if key.startswith('aggregator.')}\n",
    "pi3x_aggregator = {key:pi3x[key] for key in pi3x.keys() if key.startswith('aggregator.')}\n",
    "\n",
    "print(f'Len of pi3 \"aggregator.\": {len(pi3_aggregator)}')\n",
    "print(f'Len of pi3x \"aggregator.\": {len(pi3x_aggregator)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75564196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len of pi3 \"aggregator.\": 0\n",
      "Len of pi3x \"aggregator.\": 0\n"
     ]
    }
   ],
   "source": [
    "pi3_aggregator = {key:pi3[key] for key in pi3.keys() if 'aggregator' in key}\n",
    "pi3x_aggregator = {key:pi3x[key] for key in pi3x.keys() if 'aggregator' in key}\n",
    "\n",
    "print(f'Len of pi3 \"aggregator.\": {len(pi3_aggregator)}')\n",
    "print(f'Len of pi3x \"aggregator.\": {len(pi3x_aggregator)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
